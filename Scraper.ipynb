{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing, suppress\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import zipfile\n",
    "import io\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scraper:\n",
    "    \n",
    "    _language = 'Python'\n",
    "    _parser = 'html.parser'\n",
    "    \n",
    "    def __init__(self, year, round_nr, problem_nr, save_path):\n",
    "        self.save_path = save_path\n",
    "        self.url = 'https://www.go-hero.net/jam/' + f'{year}/solutions/{round_nr}/{problem_nr}/{self._language}'\n",
    "        self.download_links = []\n",
    "    \n",
    "    def download_all(self):\n",
    "        pathlib.Path(self.save_path).mkdir(parents=True, exist_ok=True)\n",
    "        self.get_all_download_links()\n",
    "        self._download_files()\n",
    "        \n",
    "    def get_all_download_links(self):\n",
    "        main_page = simple_get(self.url)\n",
    "        self._save_download_links_from_page(main_page)\n",
    "        \n",
    "        page = 1\n",
    "        sub_page = simple_get(self.url + f'/partial/{page}')\n",
    "        while sub_page is not None:\n",
    "            self._save_download_links_from_page(sub_page)\n",
    "            page += 1\n",
    "            sub_page = simple_get(self.url + f'/partial/{page}')\n",
    "            \n",
    "    def _save_download_links_from_page(self, url_content):\n",
    "        html = BeautifulSoup(url_content, self._parser)\n",
    "        for link_text in html.select('a'):\n",
    "            link = self._extract_download_link_from_text(link_text)\n",
    "            if link is not None:\n",
    "                self.download_links.append(link)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _extract_download_link_from_text(text):\n",
    "        try:\n",
    "            download_link = \"https://code\" + re.search('\"http://code(.*?)\"', str(text)).group(1)\n",
    "            download_link = re.sub(\"&amp;\", \"&\", download_link)\n",
    "            return download_link\n",
    "        \n",
    "        except AttributeError:\n",
    "            return None\n",
    "        \n",
    "    def _download_files(self):\n",
    "        for nr, link in enumerate(self.download_links):\n",
    "            zip_link = get(link, stream=True)\n",
    "            with zipfile.ZipFile(io.BytesIO(zip_link.content)) as zip_file:\n",
    "                with open(f'{self.save_path}/{nr}.py',\"wb\") as extracted_file:\n",
    "                    extracted_file.write(zip_file.read(zip_file.namelist()[0]))\n",
    "                \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
